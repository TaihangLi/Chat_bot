{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Understanding intents and entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_template = \"BOT : {0}\"\n",
    "user_template = \"USER : {0}\"\n",
    "\n",
    "# Define a function that responds to a user's message: respond\n",
    "def respond(message):\n",
    "    # Concatenate the user's message to the end of a standard bot respone\n",
    "    bot_message = \"I can hear you! You said: \" + message\n",
    "    # Return the result\n",
    "    return bot_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER : hello\n",
      "BOT : I can hear you! You said: hello\n"
     ]
    }
   ],
   "source": [
    "# Define a function that sends a message to the bot: send_message\n",
    "def send_message(message):\n",
    "    # Print user_template including the user_message\n",
    "    print(user_template.format(message))\n",
    "    # Get the bot's response to the message\n",
    "    response = respond(message)\n",
    "    # Print the bot template including the bot's response.\n",
    "    print(bot_template.format(response))\n",
    "\n",
    "# Send a message to the bot\n",
    "send_message(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'greet': re.compile('hello|hi|hey'), 'thankyou': re.compile('thank|thx'), 'goodbye': re.compile('bye|farewell')}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "keywords = {\n",
    "            'greet': ['hello', 'hi', 'hey'],\n",
    "            'thankyou': ['thank', 'thx'],\n",
    "            'goodbye': ['bye', 'farewell']\n",
    "           }\n",
    "# Define a dictionary of patterns\n",
    "patterns = {}\n",
    "\n",
    "# Iterate over the keywords dictionary\n",
    "for intent, value in keywords.items():\n",
    "    # Create regular expressions and compile them into pattern objects\n",
    "    patterns[intent] = re.compile('|'.join(value))\n",
    "    \n",
    "# Print the patterns\n",
    "print(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER : hello!\n",
      "BOT : Hello you! :)\n",
      "USER : bye byeee\n",
      "BOT : goodbye for now\n",
      "USER : thanks very much!\n",
      "BOT : you are very welcome\n"
     ]
    }
   ],
   "source": [
    "responses = {'greet': 'Hello you! :)', \n",
    "             'thankyou': 'you are very welcome', \n",
    "             'default': 'default message', \n",
    "             'goodbye': 'goodbye for now'\n",
    "            }\n",
    "\n",
    "# Define a function to find the intent of a message\n",
    "def match_intent(message):\n",
    "    matched_intent = None\n",
    "    for intent, pattern in patterns.items():\n",
    "        # Check if the pattern occurs in the message \n",
    "        if pattern.search(message):\n",
    "            matched_intent = intent\n",
    "    return matched_intent\n",
    "\n",
    "# Define a respond function\n",
    "def respond(message):\n",
    "    # Call the match_intent function\n",
    "    intent = match_intent(message)\n",
    "    # Fall back to the default response\n",
    "    key = \"default\"\n",
    "    if intent in responses:\n",
    "        key = intent\n",
    "    return responses[key]\n",
    "\n",
    "# Send messages\n",
    "send_message(\"hello!\")\n",
    "send_message(\"bye byeee\")\n",
    "send_message(\"thanks very much!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER : my name is David Copperfield\n",
      "BOT : Hello, David Copperfield!\n",
      "USER : call me Ishmael\n",
      "BOT : Hello, Ishmael!\n",
      "USER : people call me Cassandra\n",
      "BOT : Hello, Cassandra!\n"
     ]
    }
   ],
   "source": [
    "# Define find_name()\n",
    "def find_name(message):\n",
    "    name = None\n",
    "    # Create a pattern for checking if the keywords occur\n",
    "    name_keyword = re.compile(r\"(name|call)\")\n",
    "    # Create a pattern for finding capitalized words\n",
    "    name_pattern = re.compile('[A-Z]{1}[a-z]*')\n",
    "    if name_keyword.search(message):\n",
    "        # Get the matching words in the string\n",
    "        name_words = name_pattern.findall(message)\n",
    "        if len(name_words) > 0:\n",
    "            # Return the name if the keywords are present\n",
    "            name = ' '.join(name_words)\n",
    "    return name\n",
    "\n",
    "# Define respond()\n",
    "def respond(message):\n",
    "    # Find the name\n",
    "    name = find_name(message)\n",
    "    if name is None:\n",
    "        return \"Hi there!\"\n",
    "    else:\n",
    "        return \"Hello, {0}!\".format(name)\n",
    "\n",
    "# Send messages\n",
    "send_message(\"my name is David Copperfield\")\n",
    "send_message(\"call me Ishmael\")\n",
    "send_message(\"people call me Cassandra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "sentences = [' i want to fly from boston at 838 am and arrive in denver at 1110 in the morning', \n",
    " ' what flights are available from pittsburgh to baltimore on thursday morning', \n",
    " ' what is the arrival time in san francisco for the 755 am flight leaving washington', \n",
    " ' cheapest airfare from tacoma to orlando', \n",
    " ' round trip fares from pittsburgh to philadelphia under 1000 dollars', \n",
    " ' i need a flight tomorrow from columbus to minneapolis', \n",
    " ' what kind of aircraft is used on a flight from cleveland to dallas', \n",
    " ' show me the flights from pittsburgh to los angeles on thursday', \n",
    " ' all flights from boston to washington', \n",
    " ' what kind of ground transportation is available in denver', \n",
    " ' show me the flights from dallas to san francisco', \n",
    " ' show me the flights from san diego to newark by way of houston', \n",
    " ' what is the cheapest flight from boston to bwi', \n",
    " ' all flights to baltimore after 6 pm', \n",
    " ' show me the first class fares from boston to denver', \n",
    " ' show me the ground transportation in denver', \n",
    " ' all flights from denver to pittsburgh leaving after 6 pm and before 7 pm', \n",
    " ' i need information on flights for tuesday leaving baltimore for dallas dallas to boston and boston to baltimore', \n",
    " ' please give me the flights from boston to pittsburgh on thursday of next week', \n",
    " ' i would like to fly from denver to pittsburgh on united airlines', \n",
    " ' show me the flights from san diego to newark', \n",
    " ' please list all first class flights on united from denver to baltimore', \n",
    " ' what kinds of planes are used by american airlines', \n",
    " \" i'd like to have some information on a ticket from denver to pittsburgh and atlanta\", \n",
    " \" i'd like to book a flight from atlanta to denver\", \n",
    " ' which airline serves denver pittsburgh and atlanta', \n",
    " \" show me all flights from boston to pittsburgh on wednesday of next week which leave boston after 2 o'clock pm\", \n",
    " ' atlanta ground transportation', ' i also need service from dallas to boston arriving by noon', \n",
    " ' show me the cheapest round trip fare from baltimore to dallas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10231\\Anaconda3\\lib\\site-packages\\spacy\\util.py:275: UserWarning: [W031] Model 'en_core_web_md' (2.2.5) requires spaCy v2.2 and is incompatible with the current spaCy version (2.3.2). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "# Load the spacy model: nlp, en_core_web_md\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "# Calculate the length of sentences\n",
    "n_sentences = len(sentences)\n",
    "\n",
    "# Calculate the dimensionality of nlp\n",
    "embedding_dim = nlp.vocab.vectors_length\n",
    "\n",
    "# Initialize the array with zeros: X\n",
    "X = np.zeros((n_sentences, embedding_dim))\n",
    "\n",
    "# Iterate over the sentences\n",
    "for idx, sentence in enumerate(sentences):\n",
    "    # Pass each each sentence to the nlp object to create a document\n",
    "    doc = nlp(sentence)\n",
    "    # Save the document's .vector attribute to the corresponding row in X\n",
    "    X[idx, :] = doc.vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Intent classification with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "X_train = pd.read_csv('X_train.csv')\n",
    "X_test = pd.read_csv('X_test.csv')\n",
    "y_train = pd.read_csv('y_train.csv')['label']\n",
    "y_test = pd.read_csv('y_test.csv')['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10231\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted 162 correctly out of 201 test examples.\n"
     ]
    }
   ],
   "source": [
    "# Import SVC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Create a support vector classifier\n",
    "clf = SVC()\n",
    "\n",
    "# Fit the classifier using the training data\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "# Predict the labels of the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Count the number of correct predictions\n",
    "n_correct = 0\n",
    "for i in range(len(y_test)):\n",
    "    if y_pred[i] == y_test[i]:\n",
    "        n_correct += 1\n",
    "        \n",
    "print(\"Predicted {0} correctly out of {1} test examples.\".format(n_correct, len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Entity extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DATE': '2010', 'ORG': 'Google', 'PERSON': 'Mary'}\n",
      "{'DATE': '1999', 'ORG': 'MIT', 'PERSON': None}\n"
     ]
    }
   ],
   "source": [
    "## Using spaCy's entity recogniser\n",
    "\n",
    "# Define included entities\n",
    "include_entities = ['DATE', 'ORG', 'PERSON']\n",
    "\n",
    "# Define extract_entities()\n",
    "def extract_entities(message):\n",
    "    # Create a dict to hold the entities\n",
    "    ents = dict.fromkeys(include_entities)\n",
    "    # Create a spacy document\n",
    "    doc = nlp(message)\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in include_entities:\n",
    "            # Save interesting entities\n",
    "            ents[ent.label_] = ent.text\n",
    "    return ents\n",
    "\n",
    "print(extract_entities('friends called Mary who have worked at Google since 2010'))\n",
    "print(extract_entities('people who graduated from MIT in 1999'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Assigning roles using spaCy's parser\n",
    "def entity_type(word):\n",
    "    _type = None\n",
    "    if word.text in colors:\n",
    "        _type = \"color\"\n",
    "    elif word.text in items:\n",
    "        _type = \"item\"\n",
    "    return _type\n",
    "\n",
    "colors = ['black', 'red', 'blue']\n",
    "items = ['shoes', 'handback', 'jacket', 'jeans']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Assigning roles using spaCy's parser\n",
    "\n",
    "# Create the document\n",
    "doc = ____\n",
    "\n",
    "# Iterate over parents in parse tree until an item entity is found\n",
    "def find_parent_item(word):\n",
    "    # Iterate over the word's ancestors\n",
    "    for parent in ____:\n",
    "        # Check for an \"item\" entity\n",
    "        if entity_type(____) == \"____\":\n",
    "            return parent.text\n",
    "    return None\n",
    "\n",
    "# For all color entities, find their parent item\n",
    "def assign_colors(doc):\n",
    "    # Iterate over the document\n",
    "    for word in ____:\n",
    "        # Check for \"color\" entities\n",
    "        if entity_type(word) == \"____\":\n",
    "            # Find the parent\n",
    "            item =  ____\n",
    "            print(\"item: {0} has color : {1}\".format(item, word))\n",
    "\n",
    "# Assign the colors\n",
    "____ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Robust NLU with Rasa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Rasa NLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10231\\Anaconda3\\lib\\site-packages\\spacy\\util.py:275: UserWarning: [W031] Model 'en_core_web_md' (2.2.5) requires spaCy v2.2 and is incompatible with the current spaCy version (2.3.2). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\10231\\AppData\\Roaming\\Python\\Python37\\site-packages\\rasa_nlu\\training_data\\training_data.py:176: UserWarning: Intent 'None' has only 1 training examples! Minimum is 2, training may fail.\n",
      "  self.MIN_EXAMPLES_PER_INTENT))\n",
      "C:\\Users\\10231\\AppData\\Roaming\\Python\\Python37\\site-packages\\rasa_nlu\\training_data\\training_data.py:184: UserWarning: Entity 'area' has only 1 training examples! minimum is 2, training may fail.\n",
      "  self.MIN_EXAMPLES_PER_ENTITY))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n",
      "{'intent': {'name': 'restaurant_search', 'confidence': 0.6613460144663318}, 'entities': [{'start': 18, 'end': 25, 'value': 'mexican', 'entity': 'cuisine', 'confidence': 0.652738841752258, 'extractor': 'CRFEntityExtractor'}, {'start': 44, 'end': 49, 'value': 'north', 'entity': 'location', 'confidence': 0.840130232993451, 'extractor': 'CRFEntityExtractor'}], 'intent_ranking': [{'name': 'restaurant_search', 'confidence': 0.6613460144663318}, {'name': 'goodbye', 'confidence': 0.11494089149590193}, {'name': 'location', 'confidence': 0.06706916189156273}, {'name': 'hotel_search', 'confidence': 0.060250658807240266}, {'name': 'affirm', 'confidence': 0.05194592653717817}, {'name': 'greet', 'confidence': 0.04444734680178499}], 'text': \"I'm looking for a Mexican restaurant in the North of town\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from rasa_nlu.training_data import load_data\n",
    "from rasa_nlu.config import RasaNLUModelConfig\n",
    "from rasa_nlu.model import Trainer\n",
    "from rasa_nlu import config\n",
    "\n",
    "\n",
    "# Create a trainer\n",
    "trainer = Trainer(config.load(\"config_spacy.yml\"))\n",
    "\n",
    "# Load the training data\n",
    "training_data = load_data('demo-rasa.json')\n",
    "\n",
    "# Create an interpreter by training the model\n",
    "interpreter = trainer.train(training_data)\n",
    "\n",
    "# Try it out\n",
    "print(interpreter.parse(\"I'm looking for a Mexican restaurant in the North of town\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Data-efficient entity recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intent': {'name': 'restaurant_search', 'confidence': 0.6275842256508134}, 'entities': [{'start': 8, 'end': 15, 'value': 'chinese', 'entity': 'cuisine', 'confidence': 0.6057065130162513, 'extractor': 'CRFEntityExtractor', 'processors': ['EntitySynonymMapper']}, {'start': 28, 'end': 34, 'value': 'centre', 'entity': 'location', 'confidence': 0.9343784028432665, 'extractor': 'CRFEntityExtractor'}], 'intent_ranking': [{'name': 'restaurant_search', 'confidence': 0.6275842256508134}, {'name': 'goodbye', 'confidence': 0.11703208416583816}, {'name': 'location', 'confidence': 0.07739500832647572}, {'name': 'affirm', 'confidence': 0.06591564824023495}, {'name': 'greet', 'confidence': 0.056273525245450276}, {'name': 'hotel_search', 'confidence': 0.055799508371187384}], 'text': 'show me Chinese food in the centre of town'}\n",
      "{'intent': {'name': 'restaurant_search', 'confidence': 0.7014494974447648}, 'entities': [{'start': 10, 'end': 16, 'value': 'indian', 'entity': 'cuisine', 'confidence': 0.8010084607918555, 'extractor': 'CRFEntityExtractor'}, {'start': 35, 'end': 39, 'value': 'west', 'entity': 'location', 'confidence': 0.8313945895151044, 'extractor': 'CRFEntityExtractor'}], 'intent_ranking': [{'name': 'restaurant_search', 'confidence': 0.7014494974447648}, {'name': 'goodbye', 'confidence': 0.09396229226870308}, {'name': 'hotel_search', 'confidence': 0.06129843505648317}, {'name': 'location', 'confidence': 0.05388080830329284}, {'name': 'affirm', 'confidence': 0.04925149411220387}, {'name': 'greet', 'confidence': 0.04015747281455242}], 'text': 'I want an Indian restaurant in the west'}\n",
      "{'intent': {'name': 'restaurant_search', 'confidence': 0.3796242424726088}, 'entities': [{'start': 39, 'end': 45, 'value': 'center', 'entity': 'location', 'confidence': 0.4956520778184529, 'extractor': 'CRFEntityExtractor'}], 'intent_ranking': [{'name': 'restaurant_search', 'confidence': 0.3796242424726088}, {'name': 'affirm', 'confidence': 0.22658977001235142}, {'name': 'goodbye', 'confidence': 0.22336823660214233}, {'name': 'greet', 'confidence': 0.06074968437171271}, {'name': 'hotel_search', 'confidence': 0.059380470696523996}, {'name': 'location', 'confidence': 0.05028759584466051}], 'text': 'are there any good pizza places in the center?'}\n"
     ]
    }
   ],
   "source": [
    "print(interpreter.parse(\"show me Chinese food in the centre of town\"))\n",
    "print(interpreter.parse(\"I want an Indian restaurant in the west\"))\n",
    "print(interpreter.parse(\"are there any good pizza places in the center?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Assigning roles using spaCy's parser\n",
    "\n",
    "# Create the document\n",
    "doc = nlp(\"Let us see that jacket in red and some blue jeans!\")\n",
    "\n",
    "# Iterate over parents in parse tree until an item entity is found\n",
    "def find_parent_item(word):\n",
    "    # Iterate over the word's ancestors\n",
    "    for parent in list(word.ancestors):\n",
    "        # Check for an \"item\" entity\n",
    "        if entity_type(parent) == \"item\":\n",
    "            return parent.text\n",
    "    return None\n",
    "\n",
    "# For all color entities, find their parent item\n",
    "def assign_colors(doc):\n",
    "    # Iterate over the document\n",
    "    for word in doc:\n",
    "        # Check for \"color\" entities\n",
    "        if entity_type(word) == \"color\":\n",
    "            # Find the parent\n",
    "            item =  find_parent_item(word)\n",
    "            print(\"item: {0} has color : {1}\".format(item, word))\n",
    "\n",
    "# Assign the colors\n",
    "assign_colors(doc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Assigning roles using spaCy's parser\n",
    "\n",
    "# Create the document\n",
    "doc = nlp(\"I like to wear a blue jacket and a red jean.\")\n",
    "# Iterate over parents in parse tree until an item entity is found\n",
    "def find_parent_item(word):\n",
    "    # Iterate over the word's ancestors\n",
    "    for parent in word.ancestors:\n",
    "        # Check for an \"item\" entity\n",
    "        if entity_type(parent) == \"item\":\n",
    "            return parent.text\n",
    "    return None\n",
    "\n",
    "# For all color entities, find their parent item\n",
    "def assign_colors(doc):\n",
    "    # Iterate over the document\n",
    "    for word in doc:\n",
    "        # Check for \"color\" entities\n",
    "        if entity_type(word) == \"color\":\n",
    "            # Find the parent\n",
    "            item =  find_parent_item(word)\n",
    "            print(\"item: {0} has color : {1}\".format(item, word))\n",
    "\n",
    "# Assign the colors\n",
    "assign_colors(doc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
